+++
# 0 -> 'Forthcoming',
# 1 -> 'Preprint',
# 2 -> 'Journal',
# 3 -> 'Conference Proceedings',
# 4 -> 'Book chapter',
# 5 -> 'Thesis'

title = "Human-like Affective Cognition in Foundation Models"
date = "2024-09-20"
authors = ["K. Gandhi","Z. Lynch","J. Fränken","K. Patterson","S. Wambu","T. Gerstenberg","D. C. Ong","N. D. Goodman"]
publication_types = ["1"]
publication_short = "_arXiv_"
publication = "Gandhi K., Lynch Z., Fränken J., Patterson K., Wambu S., Gerstenberg T., Ong D. C., Goodman N. D. (2024). Human-like Affective Cognition in Foundation Models. _arXiv_."
abstract = "Understanding emotions is fundamental to human interaction and experience. Humans easily infer emotions from situations or facial expressions, situations from emotions, and do a variety of other affective cognition. How adept is modern AI at these inferences? We introduce an evaluation framework for testing affective cognition in foundation models. Starting from psychological theory, we generate 1,280 diverse scenarios exploring relationships between appraisals, emotions, expressions, and outcomes. We evaluate the abilities of foundation models (GPT-4, Claude-3, Gemini-1.5-Pro) and humans (N = 567) across carefully selected conditions. Our results show foundation models tend to agree with human intuitions, matching or exceeding interparticipant agreement. In some conditions, models are ``superhuman'' -- they better predict modal human judgements than the average human. All models benefit from chain-of-thought reasoning. This suggests foundation models have acquired a human-like understanding of emotions and their influence on beliefs and behavior."
image_preview = ""
selected = false
projects = []
#url_pdf = "papers/gandhi2024affective.pdf"
url_preprint = "https://arxiv.org/abs/2409.11733"
url_code = ""
url_dataset = ""
url_slides = ""
url_video = ""
url_poster = ""
url_source = ""
#url_custom = [{name = "Github", url = ""}]
math = true
highlight = true
[header]
# image = "publications/gandhi2024affective.png"
caption = ""
+++