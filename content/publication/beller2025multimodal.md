+++
# 0 -> 'Forthcoming',
# 1 -> 'Preprint',
# 2 -> 'Journal',
# 3 -> 'Conference Proceedings',
# 4 -> 'Book chapter',
# 5 -> 'Thesis'

title = "Multimodal inference through mental simulation"
date = "2025-09-12"
year = "2025"
authors = ["A. Beller","Y. Xu","M. Siegel","S. Grant","A. Brown","J. B Tenenbaum","S. W Linderman","T. Gerstenberg"]
publication_types = ["1"]
publication_short = "_PsyArXiv_"
publication = "Beller, A., Xu, Y., Siegel, M., Grant, S., Brown, A., Tenenbaum, J. B., Linderman, S. W., Gerstenberg, T. (2025). Multimodal inference through mental simulation. _PsyArXiv_"
abstract = "The ability to infer the past from what we perceive in the present is a key capacity of human cognition. Witnessing a broken vase, humans will automatically bring to mind a causal story of what happened. Multiple sources of sensory evidence can support this inference. Seeing the broken pottery tells you something, but hearing the crash tells you even more. In this work, we explore people's inferences about the past from multimodal evidence. We present a physical reasoning paradigm called Plinko. In the prediction task, participants must determine where a ball that is dropped into a box with obstacles will land. A computational model that uses mental simulation in an Intuitive Physics Engine captures participant predictions very well. In the inference task, participants must infer which hole in the box the ball fell from. Across conditions, participants are presented with different combinations of visual and auditory cues, and must combine this information to determine what happened. We develop a sequential sampling model that selectively simulates from promising hypotheses, and demonstrate that this model accurately captures participants' judgments and eye-movements. By coordinating sensory evidence in an underlying causal representation of the physical world, this simulation approach is able to capture complex multimodal inferences that go beyond traditional approaches to multimodal integration."
image_preview = ""
selected = false
projects = []
url_pdf = "papers/beller2025multimodal.pdf"
url_preprint = "https://osf.io/preprints/psyarxiv/x2tj9"
url_code = ""
url_dataset = ""
url_slides = ""
url_video = ""
url_poster = ""
url_source = ""
#url_custom = [{name = "Github", url = ""}]
math = true
highlight = true
[header]
# image = "publications/beller2025multimodal.png"
caption = ""
+++