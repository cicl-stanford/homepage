<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>3 on Causality in Cognition Lab</title>
    <link>https://cicl.stanford.edu/publication_types/3/</link>
    <description>Recent content in 3 on Causality in Cognition Lab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2024 Tobias Gerstenberg</copyright>
    <lastBuildDate>Sun, 12 May 2024 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://cicl.stanford.edu/publication_types/3/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Towards a computational model of responsibility judgments in sequential human-AI collaboration</title>
      <link>https://cicl.stanford.edu/publication/tsirtsis2024sequential/</link>
      <pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/tsirtsis2024sequential/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Without his cookies, he&#39;s just a monster: A counterfactual simulation model of social explanation</title>
      <link>https://cicl.stanford.edu/publication/brockbank2024monster/</link>
      <pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/brockbank2024monster/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chain versus common cause: Biased causal strength judgments in humans and large language models</title>
      <link>https://cicl.stanford.edu/publication/keshmirian2024chain/</link>
      <pubDate>Sat, 11 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/keshmirian2024chain/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Do as I explain: Explanations communicate optimal interventions</title>
      <link>https://cicl.stanford.edu/publication/kirfel2024do/</link>
      <pubDate>Thu, 09 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/kirfel2024do/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Biased causal strength judgments in humans and large language models</title>
      <link>https://cicl.stanford.edu/publication/keshmirian2024biased/</link>
      <pubDate>Fri, 03 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/keshmirian2024biased/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Procedural dilemma generation for evaluating moral reasoning in humans and language models</title>
      <link>https://cicl.stanford.edu/publication/franken2024rails/</link>
      <pubDate>Wed, 17 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/franken2024rails/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Anticipating the risks and benefits of counterfactual world simulation models</title>
      <link>https://cicl.stanford.edu/publication/kirfel2023anticipating/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/kirfel2023anticipating/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Off The Rails: Procedural Dilemma Generation for Moral Reasoning</title>
      <link>https://cicl.stanford.edu/publication/franken2023rails/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/franken2023rails/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Social Contract AI: Aligning AI Assistants with Implicit Group Norms</title>
      <link>https://cicl.stanford.edu/publication/franken2023social/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/franken2023social/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MoCa: Measuring human-language model alignment on causal and moral judgment tasks</title>
      <link>https://cicl.stanford.edu/publication/nie2023moca/</link>
      <pubDate>Fri, 20 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/nie2023moca/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Realism of Visual, Auditory, and Haptic Cues in Phenomenal Causality</title>
      <link>https://cicl.stanford.edu/publication/chase2023realism/</link>
      <pubDate>Thu, 29 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/chase2023realism/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Understanding Social Reasoning in Language Models with Language Models</title>
      <link>https://cicl.stanford.edu/publication/gandhi2023understanding/</link>
      <pubDate>Tue, 27 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gandhi2023understanding/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A computational model of responsibility judgments from counterfactual simulations and intention inferences</title>
      <link>https://cicl.stanford.edu/publication/wu2023computational/</link>
      <pubDate>Thu, 11 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/wu2023computational/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Father, don&#39;t forgive them, for they could have known what they&#39;re doing</title>
      <link>https://cicl.stanford.edu/publication/kirfel2023willful/</link>
      <pubDate>Thu, 11 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/kirfel2023willful/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Show and tell: Learning causal structures from observations and explanations</title>
      <link>https://cicl.stanford.edu/publication/nam2023show/</link>
      <pubDate>Thu, 11 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/nam2023show/</guid>
      <description></description>
    </item>
    
    <item>
      <title>You are what you&#39;re for: Essentialist categorization in large language models</title>
      <link>https://cicl.stanford.edu/publication/zhang2023llm/</link>
      <pubDate>Thu, 11 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/zhang2023llm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Semantics for Causing, Enabling, and Preventing Verbs Using Structural Causal Models</title>
      <link>https://cicl.stanford.edu/publication/cao2023semantics/</link>
      <pubDate>Wed, 10 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/cao2023semantics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Causal Reasoning Across Agents and Objects</title>
      <link>https://cicl.stanford.edu/publication/gonzalez2023agents/</link>
      <pubDate>Wed, 10 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gonzalez2023agents/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning what matters: Causal abstraction in human inference</title>
      <link>https://cicl.stanford.edu/publication/shin2023abstraction/</link>
      <pubDate>Tue, 09 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/shin2023abstraction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Teleology and generics</title>
      <link>https://cicl.stanford.edu/publication/rose2023teleology/</link>
      <pubDate>Mon, 08 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/rose2023teleology/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Explanations can reduce overreliance on AI systems during decision-making</title>
      <link>https://cicl.stanford.edu/publication/vasconcelos2023explanations/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/vasconcelos2023explanations/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Stop, children what&#39;s that sound? Multi-modal inference through mental simulation</title>
      <link>https://cicl.stanford.edu/publication/outa2022stop/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/outa2022stop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>That was close! A counterfactual simulation model of causal judgments about decisions</title>
      <link>https://cicl.stanford.edu/publication/wu2022close/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/wu2022close/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Looking into the past: Eye-tracking mental simulation in physical inference</title>
      <link>https://cicl.stanford.edu/publication/beller2022looking/</link>
      <pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/beller2022looking/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Do humans trust advice more if it comes from AI? an analysis of human-AI interactions</title>
      <link>https://cicl.stanford.edu/publication/vodrahalli2022humans/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/vodrahalli2022humans/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Uncalibrated models can improve human-AI collaboration</title>
      <link>https://cicl.stanford.edu/publication/vodrahalli2022uncalibrated/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/vodrahalli2022uncalibrated/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Who went fishing? Inferences from social evaluations</title>
      <link>https://cicl.stanford.edu/publication/davis2021fishing/</link>
      <pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/davis2021fishing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The language of causation</title>
      <link>https://cicl.stanford.edu/publication/beller2020language/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/beller2020language/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Whom will Granny thank? Thinking about what could have been informs children&#39;s inferences about relative helpfulness</title>
      <link>https://cicl.stanford.edu/publication/bridgers2020granny/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/bridgers2020granny/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Explaining intuitive difficulty judgments by modeling physical effort and risk</title>
      <link>https://cicl.stanford.edu/publication/yildirim2019difficulty/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/yildirim2019difficulty/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tiptoeing around it: Inference from absence in potentially offensive speech</title>
      <link>https://cicl.stanford.edu/publication/gates2018tiptoeing/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gates2018tiptoeing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What happened? Reconstructing the past from vision and sound</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2018what/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2018what/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Causal learning from interventions and dynamics in continuous time</title>
      <link>https://cicl.stanford.edu/publication/bramley2017continuous/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/bramley2017continuous/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Faulty towers: A hypothetical simulation model of physical support</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2017faulty/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2017faulty/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Marbles in inaction: Counterfactual simulation and causation by omission</title>
      <link>https://cicl.stanford.edu/publication/stephan2017marbles/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/stephan2017marbles/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Physical problem solving: Joint planning with symbolic, geometric, and dynamic constraints</title>
      <link>https://cicl.stanford.edu/publication/yildirim2017problem/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/yildirim2017problem/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Implicit measurement of motivated causal attribution</title>
      <link>https://cicl.stanford.edu/publication/niemi2016implicit/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/niemi2016implicit/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Natural science: Active learning in dynamic physical microworlds</title>
      <link>https://cicl.stanford.edu/publication/bramley2016natural/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/bramley2016natural/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Understanding ``almost&#39;&#39;: Empirical and computational studies of near misses</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2016almost/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2016almost/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Go fishing! Responsibility judgments when cooperation breaks down</title>
      <link>https://cicl.stanford.edu/publication/allen2015fishing/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/allen2015fishing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How, whether, why: Causal judgments as counterfactual contrasts</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2015how/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2015how/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inference of intention and permissibility in moral decision making</title>
      <link>https://cicl.stanford.edu/publication/kleiman-weiner2015intention/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/kleiman-weiner2015intention/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Responsibility judgments in voting scenarios</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2015voting/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2015voting/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Causal supersession</title>
      <link>https://cicl.stanford.edu/publication/kominsky2014supersession/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/kominsky2014supersession/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From counterfactual simulation to causal judgment</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2014simulation/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2014simulation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The order of things: Inferring causal structure from temporal patterns</title>
      <link>https://cicl.stanford.edu/publication/bramley2014order/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/bramley2014order/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Wins above replacement: Responsibility attributions as counterfactual replacements</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2014replacement/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2014replacement/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Back on track: Backtracking in counterfactual reasoning</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2013back/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2013back/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Noisy Newtons: Unifying process and dependency accounts of causal attribution</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2012noisy/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2012noisy/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ping Pong in Church: Productive use of concepts in human probabilistic inference</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2012pingpong/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2012pingpong/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Why blame Bob? Probabilistic generative models, counterfactual reasoning, and blame attribution</title>
      <link>https://cicl.stanford.edu/publication/mccoy2012probabilistic/</link>
      <pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/mccoy2012probabilistic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Beyond outcomes: The influence of intentions and deception</title>
      <link>https://cicl.stanford.edu/publication/schaechtele2011beyond/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/schaechtele2011beyond/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Blame the skilled</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2011blame/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2011blame/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Rational order effects in responsibility attributions</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2011rational/</link>
      <pubDate>Sat, 01 Jan 2011 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2011rational/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The dice are cast: The role of intended versus actual contributions in responsibility attribution</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2010dice/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2010dice/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>