<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Causality in Cognition Lab on Causality in Cognition Lab</title>
    <link>https://cicl.stanford.edu/</link>
    <description>Recent content in Causality in Cognition Lab on Causality in Cognition Lab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2024 Tobias Gerstenberg</copyright>
    <lastBuildDate>Sun, 21 Jan 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Beyond the here and now: Counterfactual simulation in causal cognition</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2024beyond/</link>
      <pubDate>Sun, 21 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2024beyond/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From Artifacts to Human Lives: Investigating the Domain-Generality of Judgments about Purposes</title>
      <link>https://cicl.stanford.edu/publication/prinzing2024purpose/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/prinzing2024purpose/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Anticipating the risks and benefits of counterfactual world simulation models</title>
      <link>https://cicl.stanford.edu/publication/kirfel2023anticipating/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/kirfel2023anticipating/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Off The Rails: Procedural Dilemma Generation for Moral Reasoning</title>
      <link>https://cicl.stanford.edu/publication/franken2023rails/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/franken2023rails/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Social Contract AI: Aligning AI Assistants with Implicit Group Norms</title>
      <link>https://cicl.stanford.edu/publication/franken2023social/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/franken2023social/</guid>
      <description></description>
    </item>
    
    <item>
      <title>If not me, then who? Responsibility and replacement</title>
      <link>https://cicl.stanford.edu/publication/wu2023replacement/</link>
      <pubDate>Fri, 27 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/wu2023replacement/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MoCa: Measuring human-language model alignment on causal and moral judgment tasks</title>
      <link>https://cicl.stanford.edu/publication/nie2023moca/</link>
      <pubDate>Fri, 20 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/nie2023moca/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Probabilistic programs as a unifying language of thought</title>
      <link>https://cicl.stanford.edu/publication/goodman2023probabilistic/</link>
      <pubDate>Fri, 20 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/goodman2023probabilistic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Children use disagreement to infer what happened</title>
      <link>https://cicl.stanford.edu/publication/amemiya2023disagreement/</link>
      <pubDate>Sat, 09 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/amemiya2023disagreement/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A counterfactual simulation model of causal language</title>
      <link>https://cicl.stanford.edu/publication/beller2023language/</link>
      <pubDate>Tue, 04 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/beller2023language/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Realism of Visual, Auditory, and Haptic Cues in Phenomenal Causality</title>
      <link>https://cicl.stanford.edu/publication/chase2023realism/</link>
      <pubDate>Thu, 29 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/chase2023realism/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Understanding Social Reasoning in Language Models with Language Models</title>
      <link>https://cicl.stanford.edu/publication/gandhi2023understanding/</link>
      <pubDate>Tue, 27 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gandhi2023understanding/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Making a positive difference: Criticality in groups</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2023criticality/</link>
      <pubDate>Wed, 14 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2023criticality/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A computational model of responsibility judgments from counterfactual simulations and intention inferences</title>
      <link>https://cicl.stanford.edu/publication/wu2023computational/</link>
      <pubDate>Thu, 11 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/wu2023computational/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Father, don&#39;t forgive them, for they could have known what they&#39;re doing</title>
      <link>https://cicl.stanford.edu/publication/kirfel2023willful/</link>
      <pubDate>Thu, 11 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/kirfel2023willful/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
