<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Causality in Cognition Lab on Causality in Cognition Lab</title>
    <link>https://cicl.stanford.edu/</link>
    <description>Recent content in Causality in Cognition Lab on Causality in Cognition Lab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2025 Tobias Gerstenberg</copyright>
    <lastBuildDate>Fri, 31 Oct 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Spot the ball: A benchmark for visual social inference</title>
      <link>https://cicl.stanford.edu/publication/balamurugan2025ball/</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/balamurugan2025ball/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Constructing causal stories: How mental models shape memory, prediction, and generalization</title>
      <link>https://cicl.stanford.edu/publication/shin2025constructing/</link>
      <pubDate>Wed, 22 Oct 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/shin2025constructing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Probing counterfactual thinking without counterfactual language</title>
      <link>https://cicl.stanford.edu/publication/rose2025probing/</link>
      <pubDate>Wed, 01 Oct 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/rose2025probing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Actual or counterfactual? Asymmetric responsibility attributions in language models</title>
      <link>https://cicl.stanford.edu/publication/xiang2025actual/</link>
      <pubDate>Sun, 28 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/xiang2025actual/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A signaling theory of self-handicapping</title>
      <link>https://cicl.stanford.edu/publication/xiang2025handicapping/</link>
      <pubDate>Thu, 18 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/xiang2025handicapping/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multimodal inference through mental simulation</title>
      <link>https://cicl.stanford.edu/publication/beller2025multimodal/</link>
      <pubDate>Fri, 12 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/beller2025multimodal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How children map causal verbs to different causes across development</title>
      <link>https://cicl.stanford.edu/publication/rose2025cause/</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/rose2025cause/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Modeling open-world cognition as on-demand synthesis of probabilistic models</title>
      <link>https://cicl.stanford.edu/publication/wong2025modeling/</link>
      <pubDate>Tue, 22 Jul 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/wong2025modeling/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A framework for blaming willful ignorance</title>
      <link>https://cicl.stanford.edu/publication/kirfel2025framework/</link>
      <pubDate>Thu, 03 Jul 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/kirfel2025framework/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Understanding human limits in pattern recognition: A computational model of sequential reasoning in rock, paper, scissors</title>
      <link>https://cicl.stanford.edu/publication/cross2025understanding/</link>
      <pubDate>Fri, 13 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/cross2025understanding/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Causal-PIK: Causality-based physical reasoning with a physics-informed kernel</title>
      <link>https://cicl.stanford.edu/publication/pares-morlans2025pik/</link>
      <pubDate>Thu, 29 May 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/pares-morlans2025pik/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cause and fault in development</title>
      <link>https://cicl.stanford.edu/publication/rose2025fault/</link>
      <pubDate>Mon, 12 May 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/rose2025fault/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Generics revisited: Analyzing generalizations in children&#39;s books and caregivers&#39; speech</title>
      <link>https://cicl.stanford.edu/publication/yu2025generics/</link>
      <pubDate>Mon, 12 May 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/yu2025generics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How do we get to know someone? Diagnostic questions for inferring personal traits</title>
      <link>https://cicl.stanford.edu/publication/brockbank2025deep/</link>
      <pubDate>Mon, 12 May 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/brockbank2025deep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Language models assign responsibility based on actual rather than counterfactual contributions</title>
      <link>https://cicl.stanford.edu/publication/xiang2025how/</link>
      <pubDate>Mon, 12 May 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/xiang2025how/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
