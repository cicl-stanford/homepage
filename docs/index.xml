<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Causality in Cognition Lab on Causality in Cognition Lab</title>
    <link>https://cicl.stanford.edu/</link>
    <description>Recent content in Causality in Cognition Lab on Causality in Cognition Lab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2024 Tobias Gerstenberg</copyright>
    <lastBuildDate>Wed, 15 May 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Counterfactual simulation in causal cognition</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2024counterfactual/</link>
      <pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2024counterfactual/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Children use disagreement to infer what happened</title>
      <link>https://cicl.stanford.edu/publication/amemiya2024disagreement/</link>
      <pubDate>Mon, 13 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/amemiya2024disagreement/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Whodunnit? Inferring what happened from multimodal evidence</title>
      <link>https://cicl.stanford.edu/publication/wu2024whodunnit/</link>
      <pubDate>Mon, 13 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/wu2024whodunnit/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards a computational model of responsibility judgments in sequential human-AI collaboration</title>
      <link>https://cicl.stanford.edu/publication/tsirtsis2024sequential/</link>
      <pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/tsirtsis2024sequential/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Without his cookies, he&#39;s just a monster: A counterfactual simulation model of social explanation</title>
      <link>https://cicl.stanford.edu/publication/brockbank2024monster/</link>
      <pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/brockbank2024monster/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chain versus common cause: Biased causal strength judgments in humans and large language models</title>
      <link>https://cicl.stanford.edu/publication/keshmirian2024chain/</link>
      <pubDate>Sat, 11 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/keshmirian2024chain/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Do as I explain: Explanations communicate optimal interventions</title>
      <link>https://cicl.stanford.edu/publication/kirfel2024do/</link>
      <pubDate>Thu, 09 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/kirfel2024do/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Biased causal strength judgments in humans and large language models</title>
      <link>https://cicl.stanford.edu/publication/keshmirian2024biased/</link>
      <pubDate>Fri, 03 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/keshmirian2024biased/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Resource-rational moral judgment</title>
      <link>https://cicl.stanford.edu/publication/wu2024resource/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/wu2024resource/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Self-supervised alignment with mutual information: Learning to follow principles without preference labels</title>
      <link>https://cicl.stanford.edu/publication/franken2024sami/</link>
      <pubDate>Mon, 22 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/franken2024sami/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Procedural dilemma generation for evaluating moral reasoning in humans and language models</title>
      <link>https://cicl.stanford.edu/publication/franken2024rails/</link>
      <pubDate>Wed, 17 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/franken2024rails/</guid>
      <description></description>
    </item>
    
    <item>
      <title>STaR-GATE: Teaching Language Models to Ask Clarifying Questions</title>
      <link>https://cicl.stanford.edu/publication/andukuri2024stargate/</link>
      <pubDate>Sun, 31 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/andukuri2024stargate/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From Artifacts to Human Lives: Investigating the Domain-Generality of Judgments about Purposes</title>
      <link>https://cicl.stanford.edu/publication/prinzing2024purpose/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/prinzing2024purpose/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Anticipating the risks and benefits of counterfactual world simulation models</title>
      <link>https://cicl.stanford.edu/publication/kirfel2023anticipating/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/kirfel2023anticipating/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Off The Rails: Procedural Dilemma Generation for Moral Reasoning</title>
      <link>https://cicl.stanford.edu/publication/franken2023rails/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/franken2023rails/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
