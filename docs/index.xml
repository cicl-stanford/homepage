<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Causality in Cognition Lab on Causality in Cognition Lab</title>
    <link>https://cicl.stanford.edu/</link>
    <description>Recent content in Causality in Cognition Lab on Causality in Cognition Lab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2024 Tobias Gerstenberg</copyright>
    <lastBuildDate>Fri, 04 Oct 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>MARPLE: A Benchmark for Long-Horizon Inference</title>
      <link>https://cicl.stanford.edu/publication/jin2024marple/</link>
      <pubDate>Fri, 04 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/jin2024marple/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Causation, Meaning, and Communication</title>
      <link>https://cicl.stanford.edu/publication/beller2024causation/</link>
      <pubDate>Fri, 20 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/beller2024causation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Human-like Affective Cognition in Foundation Models</title>
      <link>https://cicl.stanford.edu/publication/gandhi2024affective/</link>
      <pubDate>Fri, 20 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gandhi2024affective/</guid>
      <description></description>
    </item>
    
    <item>
      <title>To Err is Robotic: Rapid Value-Based Trial-and-Error during Deployment</title>
      <link>https://cicl.stanford.edu/publication/du2024robotic/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/du2024robotic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Counterfactual simulation in causal cognition</title>
      <link>https://cicl.stanford.edu/publication/gerstenberg2024counterfactual/</link>
      <pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/gerstenberg2024counterfactual/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Children use disagreement to infer what happened</title>
      <link>https://cicl.stanford.edu/publication/amemiya2024disagreement/</link>
      <pubDate>Mon, 13 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/amemiya2024disagreement/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Whodunnit? Inferring what happened from multimodal evidence</title>
      <link>https://cicl.stanford.edu/publication/wu2024whodunnit/</link>
      <pubDate>Mon, 13 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/wu2024whodunnit/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards a computational model of responsibility judgments in sequential human-AI collaboration</title>
      <link>https://cicl.stanford.edu/publication/tsirtsis2024sequential/</link>
      <pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/tsirtsis2024sequential/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Without his cookies, he&#39;s just a monster: A counterfactual simulation model of social explanation</title>
      <link>https://cicl.stanford.edu/publication/brockbank2024monster/</link>
      <pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/brockbank2024monster/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chain versus common cause: Biased causal strength judgments in humans and large language models</title>
      <link>https://cicl.stanford.edu/publication/keshmirian2024chain/</link>
      <pubDate>Sat, 11 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/keshmirian2024chain/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Do as I explain: Explanations communicate optimal interventions</title>
      <link>https://cicl.stanford.edu/publication/kirfel2024do/</link>
      <pubDate>Thu, 09 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/kirfel2024do/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Biased causal strength judgments in humans and large language models</title>
      <link>https://cicl.stanford.edu/publication/keshmirian2024biased/</link>
      <pubDate>Fri, 03 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/keshmirian2024biased/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Resource-rational moral judgment</title>
      <link>https://cicl.stanford.edu/publication/wu2024resource/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/wu2024resource/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Procedural dilemma generation for evaluating moral reasoning in humans and language models</title>
      <link>https://cicl.stanford.edu/publication/franken2024rails/</link>
      <pubDate>Wed, 17 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/franken2024rails/</guid>
      <description></description>
    </item>
    
    <item>
      <title>STaR-GATE: Teaching Language Models to Ask Clarifying Questions</title>
      <link>https://cicl.stanford.edu/publication/andukuri2024stargate/</link>
      <pubDate>Sun, 31 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://cicl.stanford.edu/publication/andukuri2024stargate/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
